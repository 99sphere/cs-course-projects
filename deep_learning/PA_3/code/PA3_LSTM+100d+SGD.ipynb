{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import emo_utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from collections import deque\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "def word_embedding(train_X):\n",
    "    new_train_X = []\n",
    "    for sentence in train_X:\n",
    "        temp = sentence.split()\n",
    "        blank = [x*0 for x in range(100)]\n",
    "        result = []\n",
    "        for word in temp:\n",
    "            word = word.lower()\n",
    "            result.append(word_to_vec_map[word])\n",
    "        while len(result) < 10:\n",
    "            result.append(blank)\n",
    "        new_train_X.append(result)\n",
    "    return new_train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y = utils.read_csv(\"train_emoji.csv\")\n",
    "test_X, test_Y = utils.read_csv(\"test_emoji.csv\")\n",
    "words_to_index, index_to_words, word_to_vec_map = utils.read_glove_vecs(\"glove.6B.100d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_train_X = word_embedding(train_X)\n",
    "embedded_test_X = word_embedding(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 100)\n",
      "(132, 10, 100)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(embedded_train_X[0]).shape)\n",
    "print(np.array(embedded_train_X).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find Linear\n",
    "class Linear:\n",
    "    def __init__(self, input_size, output_size, learning_rate = 0.01):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.W = np.random.randn(input_size, output_size)*0.01\n",
    "        self.b = np.zeros((1, output_size))\n",
    "\n",
    "    def forward(self, S):\n",
    "        self.input = S\n",
    "        self.output = np.dot(S, self.W) + self.b\n",
    "        return  self.output\n",
    "    \n",
    "    def backward(self, Z):\n",
    "        S = self.input\n",
    "        gradient = np.dot(Z, self.W.T)\n",
    "        delta_W = np.dot(S.T, Z)\n",
    "        delta_b  = Z.mean(axis=0)*S.shape[0]\n",
    "        self.W = self.W - self.learning_rate * delta_W  \n",
    "        self.b = self.b - self.learning_rate * delta_b\n",
    "        return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def dsigmoid(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def dtanh(x):\n",
    "    return 1 - np.tanh(x) * np.tanh(x)\n",
    "\n",
    "def softmax(x, axis=None):\n",
    "    return np.exp(x - logsumexp(x, axis=axis, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNOptimizer(object):\n",
    "    def __init__(self,lr = 0.01,gradient_clipping = True):\n",
    "        self.lr = lr\n",
    "        self.gradient_clipping = gradient_clipping\n",
    "        self.first = True\n",
    "\n",
    "    def step(self):\n",
    "        for layer in self.model.layers:\n",
    "            for key in layer.params.keys():\n",
    "                if self.gradient_clipping:\n",
    "                    np.clip(layer.params[key]['deriv'], -2, 2, layer.params[key]['deriv'])\n",
    "                self._update_rule(param=layer.params[key]['value'], grad=layer.params[key]['deriv'])\n",
    "\n",
    "    def _update_rule(self, **kwargs):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD(RNNOptimizer):\n",
    "    def __init__(self,\n",
    "                 lr= 0.01,\n",
    "                 gradient_clipping = True):\n",
    "        super().__init__(lr, gradient_clipping)\n",
    "\n",
    "    def _update_rule(self, **kwargs):\n",
    "\n",
    "        update = self.lr*kwargs['grad']\n",
    "        kwargs['param'] -= update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxCrossEntropy:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, result, Y):\n",
    "        answers = result[np.arange(len(result)),Y]\n",
    "        cross_entropy = - answers + np.log(np.sum(np.exp(result),axis=-1))\n",
    "        return cross_entropy\n",
    "\n",
    "    def backward(self, result, Y):\n",
    "        ones_for_answers = np.zeros_like(result)\n",
    "        ones_for_answers[np.arange(len(result)),Y] = 1    \n",
    "        softmax = np.exp(result) / np.exp(result).sum(axis=-1,keepdims=True)\n",
    "        return (- ones_for_answers + softmax) / result.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNode:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def forward(self, X_in, H_in, C_in, params_dict):\n",
    "        self.X_in = X_in\n",
    "        self.C_in = C_in\n",
    "\n",
    "        self.Z = np.column_stack((X_in, H_in))\n",
    "        \n",
    "        self.f_int = np.dot(self.Z, params_dict['W_f']['value']) + params_dict['B_f']['value']\n",
    "        self.f = sigmoid(self.f_int)\n",
    "        \n",
    "        self.i_int = np.dot(self.Z, params_dict['W_i']['value']) + params_dict['B_i']['value']\n",
    "        self.i = sigmoid(self.i_int)\n",
    "        self.C_bar_int = np.dot(self.Z, params_dict['W_c']['value']) + params_dict['B_c']['value']\n",
    "        self.C_bar = tanh(self.C_bar_int)\n",
    "\n",
    "        self.C_out = self.f * C_in + self.i * self.C_bar\n",
    "        self.o_int = np.dot(self.Z, params_dict['W_o']['value']) + params_dict['B_o']['value']\n",
    "        self.o = sigmoid(self.o_int)\n",
    "        self.H_out = self.o * tanh(self.C_out)\n",
    "\n",
    "        self.X_out = np.dot(self.H_out, params_dict['W_v']['value']) + params_dict['B_v']['value']\n",
    "        \n",
    "        return self.X_out, self.H_out, self.C_out \n",
    "\n",
    "\n",
    "    def backward(self, X_out_grad, H_out_grad, C_out_grad, params_dict):\n",
    "    \n",
    "        params_dict['W_v']['deriv'] += np.dot(self.H_out.T, X_out_grad)\n",
    "        params_dict['B_v']['deriv'] += X_out_grad.sum(axis=0)\n",
    "\n",
    "        dh_out = np.dot(X_out_grad, params_dict['W_v']['value'].T)        \n",
    "        dh_out += H_out_grad\n",
    "                         \n",
    "        do = dh_out * tanh(self.C_out)\n",
    "        do_int = dsigmoid(self.o_int) * do\n",
    "        params_dict['W_o']['deriv'] += np.dot(self.Z.T, do_int)\n",
    "        params_dict['B_o']['deriv'] += do_int.sum(axis=0)\n",
    "\n",
    "        dC_out = dh_out * self.o * dtanh(self.C_out)\n",
    "        dC_out += C_out_grad\n",
    "        dC_bar = dC_out * self.i\n",
    "        dC_bar_int = dtanh(self.C_bar_int) * dC_bar\n",
    "        params_dict['W_c']['deriv'] += np.dot(self.Z.T, dC_bar_int)\n",
    "        params_dict['B_c']['deriv'] += dC_bar_int.sum(axis=0)\n",
    "\n",
    "        di = dC_out * self.C_bar\n",
    "        di_int = dsigmoid(self.i_int) * di\n",
    "        params_dict['W_i']['deriv'] += np.dot(self.Z.T, di_int)\n",
    "        params_dict['B_i']['deriv'] += di_int.sum(axis=0)\n",
    "\n",
    "        df = dC_out * self.C_in\n",
    "        df_int = dsigmoid(self.f_int) * df\n",
    "        params_dict['W_f']['deriv'] += np.dot(self.Z.T, df_int)\n",
    "        params_dict['B_f']['deriv'] += df_int.sum(axis=0)\n",
    "\n",
    "        dz = (np.dot(df_int, params_dict['W_f']['value'].T) + np.dot(di_int, params_dict['W_i']['value'].T) + np.dot(dC_bar_int, params_dict['W_c']['value'].T)+ np.dot(do_int, params_dict['W_o']['value'].T))\n",
    "    \n",
    "        dx_prev = dz[:, :self.X_in.shape[1]]\n",
    "        dH_prev = dz[:, self.X_in.shape[1]:]\n",
    "        dC_prev = self.f * dC_out\n",
    "\n",
    "        return dx_prev, dH_prev, dC_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMLayer:\n",
    "    def __init__(self,hidden_size,output_size,weight_scale = 0.01):\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.weight_scale = weight_scale\n",
    "        self.start_H = np.zeros((1, hidden_size))\n",
    "        self.start_C = np.zeros((1, hidden_size))        \n",
    "        self.first = True\n",
    "        self.first_backward= True\n",
    "\n",
    "        \n",
    "    def _init_params(self,input_):\n",
    "        self.vocab_size = input_.shape[2]\n",
    "        self.params = {}\n",
    "        self.params['W_f'] = {}\n",
    "        self.params['B_f'] = {}\n",
    "        self.params['W_i'] = {}\n",
    "        self.params['B_i'] = {}\n",
    "        self.params['W_c'] = {}\n",
    "        self.params['B_c'] = {}\n",
    "        self.params['W_o'] = {}\n",
    "        self.params['B_o'] = {}        \n",
    "        self.params['W_v'] = {}\n",
    "        self.params['B_v'] = {}\n",
    "        \n",
    "        self.params['W_f']['value'] = np.random.normal(loc=0.0,scale=self.weight_scale, size =(self.hidden_size + self.vocab_size, self.hidden_size))\n",
    "        self.params['B_f']['value'] = np.random.normal(loc=0.0,scale=self.weight_scale,size=(1, self.hidden_size))\n",
    "        self.params['W_i']['value'] = np.random.normal(loc=0.0,scale=self.weight_scale,size=(self.hidden_size + self.vocab_size, self.hidden_size))\n",
    "        self.params['B_i']['value'] = np.random.normal(loc=0.0,scale=self.weight_scale,size=(1, self.hidden_size))\n",
    "        self.params['W_c']['value'] = np.random.normal(loc=0.0,scale=self.weight_scale,size=(self.hidden_size + self.vocab_size, self.hidden_size))\n",
    "        self.params['B_c']['value'] = np.random.normal(loc=0.0,scale=self.weight_scale,size=(1, self.hidden_size))\n",
    "        self.params['W_o']['value'] = np.random.normal(loc=0.0,scale=self.weight_scale,size=(self.hidden_size + self.vocab_size, self.hidden_size))\n",
    "        self.params['B_o']['value'] = np.random.normal(loc=0.0,scale=self.weight_scale, size=(1, self.hidden_size))       \n",
    "        self.params['W_v']['value'] = np.random.normal(loc=0.0,scale=self.weight_scale,size=(self.hidden_size, self.output_size))\n",
    "        self.params['B_v']['value'] = np.random.normal(loc=0.0,scale=self.weight_scale,size=(1, self.output_size))\n",
    "        \n",
    "        #print(\"--------------------------------------------------------------------\")\n",
    "        #print(\"input_.shape\", input_.shape)\n",
    "        for key in self.params.keys():\n",
    "            self.params[key]['deriv'] = np.zeros_like(self.params[key]['value'])\n",
    "        self.cells = [LSTMNode() for x in range(input_.shape[1])]\n",
    "\n",
    "    def _clear_gradients(self):\n",
    "        for key in self.params.keys():\n",
    "            self.params[key]['deriv'] = np.zeros_like(self.params[key]['deriv'])\n",
    "        \n",
    "    def forward(self, x_seq_in):\n",
    "        self.first_backward= True\n",
    "\n",
    "        if self.first:\n",
    "            self._init_params(x_seq_in)\n",
    "            self.first=False\n",
    "        \n",
    "        batch_size = x_seq_in.shape[0]\n",
    "        \n",
    "        H_in = np.copy(self.start_H)\n",
    "        C_in = np.copy(self.start_C)\n",
    "        \n",
    "        H_in = np.repeat(H_in, batch_size, axis=0)\n",
    "        C_in = np.repeat(C_in, batch_size, axis=0)        \n",
    "\n",
    "        sequence_length = x_seq_in.shape[1]\n",
    "        \n",
    "        x_seq_out = np.zeros((batch_size, sequence_length, self.output_size))\n",
    "        \n",
    "        for t in range(sequence_length):\n",
    "            x_in = x_seq_in[:, t, :]\n",
    "            y_out, H_in, C_in = self.cells[t].forward(x_in, H_in, C_in, self.params)\n",
    "            x_seq_out[:, t, :] = y_out\n",
    "    \n",
    "        self.start_H = H_in.mean(axis=0, keepdims=True)\n",
    "        self.start_C = C_in.mean(axis=0, keepdims=True)        \n",
    "        \n",
    "        return x_seq_out, y_out\n",
    "\n",
    "\n",
    "    def backward(self, x_seq_out_grad):\n",
    "        batch_size = x_seq_out_grad.shape[0]\n",
    "        \n",
    "        h_in_grad = np.zeros((batch_size, self.hidden_size))\n",
    "        c_in_grad = np.zeros((batch_size, self.hidden_size))        \n",
    "        \n",
    "        num_chars = x_seq_out_grad.shape[1]\n",
    "        \n",
    "        x_seq_in_grad = np.zeros((batch_size, num_chars, self.vocab_size))\n",
    "        \n",
    "        for t in reversed(range(10)):\n",
    "            x_out_grad = x_seq_out_grad\n",
    "            grad_out, h_in_grad, c_in_grad = self.cells[t].backward(x_out_grad, h_in_grad, c_in_grad, self.params)\n",
    "            x_seq_in_grad[:, t, :] = grad_out\n",
    "        \n",
    "        return x_seq_in_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, layers, sequence_length, vocab_size, hidden_size,loss):\n",
    "        self.layers = layers\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.loss = loss\n",
    "        self.Linear = Linear(vocab_size, 5)\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            setattr(layer, 'sequence_length', sequence_length)\n",
    "\n",
    "    def forward(self, x_batch):\n",
    "\n",
    "        for layer in self.layers:\n",
    "            total, x_batch = layer.forward(x_batch)\n",
    "        #print(\"total\", total.shape)\n",
    "        #print(\"x_batch after LSTM\", x_batch.shape)\n",
    "        \n",
    "        x_batch = self.Linear.forward(x_batch)\n",
    "        #print(\"x_batch atfer Linear\", x_batch.shape)\n",
    "        return x_batch\n",
    "        \n",
    "    def backward(self, loss_grad):\n",
    "        for layer in reversed(self.layers):\n",
    "            loss_grad = layer.backward(loss_grad)\n",
    "            \n",
    "        return loss_grad\n",
    "                \n",
    "    def single_step(self, x_batch, y_batch):\n",
    "        x_batch_out = self.forward(x_batch)\n",
    "        #print(\"x_batch_out\", x_batch_out.shape)\n",
    "        predict, _ = self.predict(x_batch_out, y_batch)\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            layer._clear_gradients()\n",
    "            \n",
    "        loss = self.loss.forward(x_batch_out, y_batch)\n",
    "        loss_grad = self.loss.backward(x_batch_out, y_batch)\n",
    "        loss_grad = self.Linear.backward(loss_grad)\n",
    "        self.backward(loss_grad)\n",
    "        return loss\n",
    "\n",
    "    \n",
    "    def predict(self, X, Y):\n",
    "        pred = []\n",
    "        for probs in X:\n",
    "            pred.append(np.argmax(probs))\n",
    "        acc = 0\n",
    "        for i in range(len(Y)):\n",
    "            if pred[i] == Y[i]:\n",
    "                acc += 1\n",
    "        acc = acc/len(Y) * 100\n",
    "        return pred, acc\n",
    "    \n",
    "    def evaluate(self, x_batch, y_batch):\n",
    "        x_batch_out = self.forward(x_batch)\n",
    "        loss = self.loss.forward(x_batch_out, y_batch)\n",
    "        return loss\n",
    "    \n",
    "    def make_result(self, X, Y):\n",
    "        X_out = self.forward(X)\n",
    "        pred = []\n",
    "        for x in X_out:\n",
    "            pred.append(np.argmax(x))\n",
    "        acc = 0\n",
    "        for i in range(len(Y)):\n",
    "            if pred[i] == Y[i]:\n",
    "                acc += 1\n",
    "        acc = acc/len(Y) * 100\n",
    "        return pred, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNTrainer:\n",
    "    def __init__(self, train_X, train_Y, test_X, test_Y, model,optim):\n",
    "        self.train_X = train_X\n",
    "        self.train_Y = train_Y\n",
    "        self.test_X = test_X\n",
    "        self.test_Y = test_Y\n",
    "        self.model = model\n",
    "        self.sequence_length = self.model.sequence_length\n",
    "        self.optim = optim\n",
    "        self.train_loss_log = []\n",
    "        self.test_loss_log = []\n",
    "        self.log_step = []\n",
    "        setattr(self.optim, 'model', self.model)\n",
    "\n",
    "    def visualize_loss(self):\n",
    "        plt.plot(self.log_step, self.train_loss_log, label='train loss')\n",
    "        plt.plot(self.log_step, self.test_loss_log, label='validation loss')\n",
    "        plt.xlabel(\"num iteration\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.legend(fontsize='x-large')\n",
    "        \n",
    "    def train(self, num_iterations):\n",
    "        train_X = self.train_X\n",
    "        train_Y = self.train_Y\n",
    "        test_X = self.test_X\n",
    "        test_Y = self.test_Y \n",
    "        \n",
    "        num_iter = 0\n",
    "        \n",
    "        train_moving_average = deque(maxlen=100)\n",
    "        test_moving_average = deque(maxlen=100)\n",
    "        \n",
    "        while num_iter < num_iterations:\n",
    "            inputs_batch = np.array(train_X)\n",
    "            targets_batch = np.array(train_Y)\n",
    "            train_loss = self.model.single_step(inputs_batch, targets_batch)\n",
    "            test_loss = self.model.evaluate(np.array(test_X), np.array(test_Y))\n",
    "            train_moving_average.append(train_loss)\n",
    "            train_ma_loss = np.mean(train_moving_average)            \n",
    "            test_moving_average.append(test_loss)\n",
    "            test_ma_loss = np.mean(test_moving_average)\n",
    "            self.train_loss_log.append(train_ma_loss)\n",
    "            self.test_loss_log.append(test_ma_loss)\n",
    "            self.optim.step()\n",
    "            self.log_step.append(num_iter)\n",
    "            if num_iter % 100 == 0:\n",
    "                print(\"[Loss after %d iter] train loss: %f, test loss: %f\" % (num_iter, train_ma_loss, test_ma_loss))\n",
    "            num_iter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Loss after 0 iter] train loss: 1.609619, test loss: 1.609362\n",
      "[Loss after 100 iter] train loss: 1.597687, test loss: 1.594375\n",
      "[Loss after 200 iter] train loss: 1.579014, test loss: 1.570021\n",
      "[Loss after 300 iter] train loss: 1.565918, test loss: 1.551545\n",
      "[Loss after 400 iter] train loss: 1.558177, test loss: 1.539197\n",
      "[Loss after 500 iter] train loss: 1.554782, test loss: 1.532683\n",
      "[Loss after 600 iter] train loss: 1.553548, test loss: 1.529849\n",
      "[Loss after 700 iter] train loss: 1.552960, test loss: 1.528675\n",
      "[Loss after 800 iter] train loss: 1.552410, test loss: 1.528089\n",
      "[Loss after 900 iter] train loss: 1.551618, test loss: 1.527569\n",
      "[Loss after 1000 iter] train loss: 1.550168, test loss: 1.526650\n",
      "[Loss after 1100 iter] train loss: 1.546332, test loss: 1.523888\n",
      "[Loss after 1200 iter] train loss: 1.513958, test loss: 1.499853\n",
      "[Loss after 1300 iter] train loss: 1.301312, test loss: 1.371286\n",
      "[Loss after 1400 iter] train loss: 1.140467, test loss: 1.262178\n",
      "[Loss after 1500 iter] train loss: 1.037535, test loss: 1.155105\n",
      "[Loss after 1600 iter] train loss: 1.028964, test loss: 1.153059\n",
      "[Loss after 1700 iter] train loss: 0.943012, test loss: 1.048032\n",
      "[Loss after 1800 iter] train loss: 0.961338, test loss: 1.190895\n",
      "[Loss after 1900 iter] train loss: 0.973524, test loss: 1.365221\n",
      "[Loss after 2000 iter] train loss: 0.817942, test loss: 1.318498\n",
      "[Loss after 2100 iter] train loss: 0.733264, test loss: 1.383947\n",
      "[Loss after 2200 iter] train loss: 0.739173, test loss: 1.409110\n",
      "[Loss after 2300 iter] train loss: 0.659532, test loss: 1.208256\n",
      "[Loss after 2400 iter] train loss: 0.464630, test loss: 1.048770\n",
      "[Loss after 2500 iter] train loss: 0.320534, test loss: 0.969845\n",
      "[Loss after 2600 iter] train loss: 0.166960, test loss: 0.837612\n",
      "[Loss after 2700 iter] train loss: 0.182508, test loss: 0.880421\n",
      "[Loss after 2800 iter] train loss: 0.017738, test loss: 0.714162\n",
      "[Loss after 2900 iter] train loss: 0.007620, test loss: 0.815304\n",
      "[Loss after 3000 iter] train loss: 0.004586, test loss: 0.885565\n"
     ]
    }
   ],
   "source": [
    "layers = [LSTMLayer(hidden_size=256, output_size=100, weight_scale=0.01)]\n",
    "model = Model(layers=layers, vocab_size=100, hidden_size=256, sequence_length=10,loss=SoftmaxCrossEntropy())\n",
    "optimizer = SGD(lr=0.02, gradient_clipping=True)\n",
    "\n",
    "RNN = RNNTrainer(embedded_train_X, train_Y, embedded_test_X, test_Y, model, optimizer)\n",
    "RNN.train(3001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_to_emoji(pred):\n",
    "    for i in pred:\n",
    "        print(utils.label_to_emoji(i), end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN model accuracy for test set is 80.36%\n"
     ]
    }
   ],
   "source": [
    "pred, acc = RNN.model.make_result(np.array(embedded_test_X), test_Y)\n",
    "print(\"RNN model accuracy for test set is \"+ str(round(acc,2))+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍴 😞 ❤️ ❤️ 😄 ❤️ 😞 😄 🍴 😄 ⚾ 😞 ❤️ 😞 ⚾ 😞 😄 😄 ⚾ 🍴 ❤️ 😄 🍴 ❤️ 😞 😞 ⚾ ❤️ ⚾ 😄 ❤️ ⚾ 😞 😄 😄 ⚾ ❤️ 🍴 🍴 😄 😞 ❤️ ❤️ ⚾ 😄 ❤️ 😄 😄 😞 ⚾ 😞 ❤️ 😞 😄 😄 ❤️ "
     ]
    }
   ],
   "source": [
    "pred_to_emoji(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "RNN.visualize_loss()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
